{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dspy methodology 101\n",
    "\n",
    "1. programming\n",
    "   1. LMs (tasks)\n",
    "   2. signatures (i/o - eg `\"context: list[str], question: str -> answer: str\"`) - compiling leads to better prompts than humans write\n",
    "      1. tasks, instruct the model what it needs to do\n",
    "      2. underlying dSPY compiler will do the optimization, rather than brittle prompts\n",
    "   3. modules (ie `dspy.Predict`, `dspy.ChainOfThought`)\n",
    "      1. prompting techniques\n",
    "2. evaluation\n",
    "3. optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOC:\n",
    "* [intro](#dspy-methodology-101)\n",
    "* [LMs](#set-a-generator-lm)\n",
    "* [evaluations](#dspy-evaluations)\n",
    "  * [example-obects](#dspy-example-objects)\n",
    "* [metrics](#dspy-metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set a generator LM\n",
    "\n",
    "<a class=\"anchor\" id=\"LM\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "import os\n",
    "\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "TOGETHER_API_KEY = os.getenv(\"TOGETHER_API_KEY\")\n",
    "\n",
    "lm=dspy.LM('together_ai/deepseek-ai/DeepSeek-R1', temperature=0.1, max_tokens=2500, stop=None, cache=False, api_key=TOGETHER_API_KEY)\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dSPY evaluations\n",
    "\n",
    "- define your DSPy metric\n",
    "  - what makes outputs from your system good or bad?\n",
    "    - A metric is a function that takes examples from your data and takes the output of your system, and returns a score.\n",
    "    - you use Examples a lot in DSPy to train, test, and improve AI models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DSPy Example objects\n",
    "\n",
    "- Examples represent items in your training set and test set\n",
    "- Examples = AI-friendly data containers\n",
    "\n",
    "**ML**:\n",
    "\n",
    "- the Example objects have a `with_inputs()` method, which can mark specific fields as inputs. (The rest are just metadata or [labels](https://toloka.ai/blog/machine-learning-labels-and-features/) - A label is a description that informs an ML model what a particular data represents so that it may learn from the example)\n",
    "\n",
    "- Inputs (Features) → The data you give to the model to make a prediction.\n",
    "  - **Example**: A picture of a cat, a sentence, or a set of numbers.\n",
    "- Labels (Targets/Outputs) → The correct answer the model should learn to predict.\n",
    "  - **Example**: The word \"cat\" for an image classification model, or the correct sentiment (positive/negative) for a text review.\n",
    "\n",
    "**Example**:\n",
    "\n",
    "If you're training a spam detector:\n",
    "**Input**: An email's text\n",
    "**Label**: \"Spam\" or \"Not Spam\"\n",
    "\n",
    "```bash\n",
    "# Single Input.\n",
    "print(qa_pair.with_inputs(\"question\"))\n",
    "\n",
    "# Multiple Inputs; be careful about marking your labels as inputs unless you mean it.\n",
    "print(qa_pair.with_inputs(\"question\", \"answer\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dSPY metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "import os\n",
    "\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "TOGETHER_API_KEY = os.getenv(\"TOGETHER_API_KEY\")\n",
    "\n",
    "lm=dspy.LM('together_ai/deepseek-ai/DeepSeek-R1', temperature=0.1, max_tokens=2500, stop=None, cache=False, api_key=TOGETHER_API_KEY)\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in to Hugging Face Hub\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "if HF_TOKEN:\n",
    "    login(token=HF_TOKEN)\n",
    "    print(\"Logged in to Hugging Face Hub\")\n",
    "else:\n",
    "    print(\"HF_TOKEN not found in environment. Set this to authenticate with Hugging Face Hub.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from dspy.datasets import HotPotQA\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "dataset = HotPotQA(train_seed=1, train_size=50, eval_seed=2, dev_size=50)\n",
    "\n",
    "# Create corpus from dataset\n",
    "corpus = {}\n",
    "for example in dataset.train:\n",
    "    for title, text in zip(example.titles, example.paragraphs):\n",
    "        doc_id = f\"{title}\"\n",
    "        corpus[doc_id] = {\n",
    "            \"title\": title,\n",
    "            \"text\": text\n",
    "        }\n",
    "\n",
    "class SimpleRetriever:\n",
    "    def __init__(self, corpus):\n",
    "        self.corpus = corpus\n",
    "        self.doc_ids = list(corpus.keys())\n",
    "        self.index = self._build_index()\n",
    "\n",
    "    def _build_index(self):\n",
    "        index = defaultdict(list)\n",
    "        for doc_id, doc in self.corpus.items():\n",
    "            text = doc.get(\"text\", \"\").lower()\n",
    "            words = set(text.split())\n",
    "            for word in words:\n",
    "                index[word].append(doc_id)\n",
    "        return index\n",
    "\n",
    "    def __call__(self, query, k=3):\n",
    "        query_words = set(query.lower().split())\n",
    "        scores = defaultdict(int)\n",
    "\n",
    "        for word in query_words:\n",
    "            for doc_id in self.index.get(word, []):\n",
    "                scores[doc_id] += 1\n",
    "\n",
    "        sorted_docs = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        top_docs = sorted_docs[:k]\n",
    "\n",
    "        results = []\n",
    "        for doc_id, _ in top_docs:\n",
    "            doc = self.corpus[doc_id]\n",
    "            results.append({\n",
    "                \"id\": doc_id,\n",
    "                \"text\": doc[\"text\"],\n",
    "                \"title\": doc.get(\"title\", \"\")\n",
    "            })\n",
    "\n",
    "        return results\n",
    "\n",
    "retriever = SimpleRetriever(corpus)\n",
    "dspy.configure(rm=retriever, lm=lm)\n",
    "\n",
    "test_results = retriever(\"Who won the Nobel Prize in Physics in 1921?\", k=3)\n",
    "print(\"Retriever test:\", [p[\"text\"][:100] + \"...\" for p in test_results])\n",
    "\n",
    "class Hop(dspy.Module):\n",
    "    def __init__(self, num_docs=10, num_hops=4):\n",
    "        self.num_docs, self.num_hops = num_docs, num_hops\n",
    "        self.generate_query = dspy.ChainOfThought('claim, notes -> query')\n",
    "        self.append_notes = dspy.ChainOfThought('claim, notes, context -> new_notes: list[str], titles: list[str]')\n",
    "\n",
    "    def forward(self, claim: str) -> list[str]:\n",
    "        notes = []\n",
    "        titles = []\n",
    "\n",
    "        for _ in range(self.num_hops):\n",
    "            query = self.generate_query(claim=claim, notes=notes).query\n",
    "            context = retriever(query, k=self.num_docs)\n",
    "            prediction = self.append_notes(claim=claim, notes=notes, context=context)\n",
    "            notes.extend(prediction.new_notes)\n",
    "            titles.extend(prediction.titles)\n",
    "\n",
    "        return dspy.Prediction(notes=notes, titles=list(set(titles)))\n",
    "\n",
    "hop_search = Hop(num_docs=3, num_hops=2)\n",
    "\n",
    "result = hop_search(claim=\"The first Olympic Games were held in Athens in 1896.\")\n",
    "\n",
    "print(\"\\nNotes:\")\n",
    "for i, note in enumerate(result.notes):\n",
    "    print(f\"{i+1}. {note}\")\n",
    "\n",
    "print(\"\\nTitles:\")\n",
    "for title in result.titles:\n",
    "    print(f\"- {title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever test: ['This is document 1 about Modern Olympics. It contains information about revival in Athens. Some addi...', 'This is document 0 about Ancient Olympics. It contains information about origin in Greece. Some addi...', 'This is document 2 about Pierre de Coubertin. It contains information about Olympic movement. Some a...']\n",
      "\n",
      "Notes:\n",
      "1. Document 1 confirms the first modern Olympic Games were held in Athens in 1896, as part of their revival.\n",
      "2. «Document 1 confirms the first modern Olympic Games were held in Athens in 1896, as part of their revival.»\n",
      "\n",
      "Titles:\n",
      "- Document 1\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "import random\n",
    "\n",
    "mock_corpus = {\n",
    "    f\"doc_{i}\": {\n",
    "        \"title\": f\"Document {i}\",\n",
    "        \"text\": f\"This is document {i} about {topic}.\" +\n",
    "                f\" It contains information about {subtopic}.\" +\n",
    "                f\" Some additional details about {details}.\"\n",
    "    }\n",
    "    for i, (topic, subtopic, details) in enumerate([\n",
    "        (\"Ancient Olympics\", \"origin in Greece\", \"started in 776 BCE in Olympia\"),\n",
    "        (\"Modern Olympics\", \"revival in Athens\", \"first held in 1896\"),\n",
    "        (\"Pierre de Coubertin\", \"Olympic movement\", \"founder of the International Olympic Committee\"),\n",
    "        (\"Olympic medals\", \"gold, silver and bronze\", \"design and symbolism\"),\n",
    "        (\"Olympic torch\", \"lighting ceremony\", \"relay to the host city\"),\n",
    "        (\"Olympic rings\", \"symbol design\", \"five interlocking rings representing continents\"),\n",
    "        (\"Winter Olympics\", \"winter sports\", \"first held in 1924 in Chamonix\"),\n",
    "        (\"Olympic host cities\", \"selection process\", \"bidding and voting by IOC members\"),\n",
    "        (\"Olympic boycotts\", \"political protests\", \"notable boycotts in history\"),\n",
    "        (\"Olympic records\", \"world records\", \"fastest, highest, strongest performances\")\n",
    "    ])\n",
    "}\n",
    "\n",
    "class MockRetriever:\n",
    "    def __init__(self, corpus):\n",
    "        self.corpus = corpus\n",
    "\n",
    "    def __call__(self, query, k=3):\n",
    "        matches = []\n",
    "        query_words = set(query.lower().split())\n",
    "\n",
    "        for doc_id, doc in self.corpus.items():\n",
    "            text = doc[\"text\"].lower()\n",
    "            match_score = sum(1 for word in query_words if word in text)\n",
    "            if match_score > 0:\n",
    "                matches.append((doc_id, match_score, doc))\n",
    "\n",
    "        matches.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [\n",
    "            {\n",
    "                \"id\": doc_id,\n",
    "                \"title\": doc[\"title\"],\n",
    "                \"text\": doc[\"text\"],\n",
    "                \"long_text\": doc[\"text\"]\n",
    "            }\n",
    "            for doc_id, _, doc in matches[:k]\n",
    "        ]\n",
    "\n",
    "retriever = MockRetriever(mock_corpus)\n",
    "dspy.configure(rm=retriever)\n",
    "\n",
    "test_results = retriever(\"Olympic Games in Athens\", k=3)\n",
    "print(\"Retriever test:\", [p[\"text\"][:100] + \"...\" for p in test_results])\n",
    "\n",
    "class CustomRetrieve(dspy.Module):\n",
    "    def __init__(self, k=3):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, query):\n",
    "        if dspy.settings.rm is None:\n",
    "            raise AssertionError(\"No RM is loaded.\")\n",
    "\n",
    "        passages = dspy.settings.rm(query, k=self.k)\n",
    "        return dspy.Prediction(passages=passages)\n",
    "\n",
    "class Hop(dspy.Module):\n",
    "    def __init__(self, num_docs=10, num_hops=4):\n",
    "        self.num_docs, self.num_hops = num_docs, num_hops\n",
    "        self.generate_query = dspy.ChainOfThought('claim, notes -> query')\n",
    "        self.append_notes = dspy.ChainOfThought('claim, notes, context -> new_notes: list[str], titles: list[str]')\n",
    "        self.retrieve = CustomRetrieve()\n",
    "\n",
    "    def forward(self, claim: str) -> list[str]:\n",
    "        notes = []\n",
    "        titles = []\n",
    "\n",
    "        for _ in range(self.num_hops):\n",
    "            query = self.generate_query(claim=claim, notes=notes).query\n",
    "            context = self.retrieve(query).passages\n",
    "            prediction = self.append_notes(claim=claim, notes=notes, context=context)\n",
    "            notes.extend(prediction.new_notes)\n",
    "            titles.extend(prediction.titles)\n",
    "\n",
    "        return dspy.Prediction(notes=notes, titles=list(set(titles)))\n",
    "\n",
    "# Create an instance of the Hop class (with fewer hops for testing)\n",
    "hop_search = Hop(num_docs=3, num_hops=2)\n",
    "\n",
    "result = hop_search(claim=\"The first Olympic Games were held in Athens in 1896.\")\n",
    "\n",
    "print(\"\\nNotes:\")\n",
    "for i, note in enumerate(result.notes):\n",
    "    print(f\"{i+1}. {note}\")\n",
    "\n",
    "print(\"\\nTitles:\")\n",
    "for title in result.titles:\n",
    "    print(f\"- {title}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
